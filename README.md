# Primeros pasos con analitica en AWS

![Portada](imagen/cover.png)

 üáªüá™üá®üá± [Dev.to](https://dev.to/elizabethfuentes12) [Linkedin](https://www.linkedin.com/in/lizfue/) [GitHub](https://github.com/elizabethfuentes12/) [Twitter](https://twitter.com/elizabethfue12)

---

## Introducci√≥n üë©üèª‚Äçüíªüëã

**Data Analytics** es un concepto muy utilizado hoy en d√≠a, es casi un pecado no saber que **Data Analytics** es el proceso de recompilar, procesar y analizar datos para usarlos tomar decisiones en base a ellos.

**Data Analytics** te permite combinar datos para crear soluciones que ayuden a las empresas a decidir donde y cuando lanzar nuevos productos, cuando ofrecer descuentos, analizar gastos y buscar ahorros, es posible crear modelos de machine learning para realizar mejoras como customer personalization, detenci√≥n de fraude, alertas en tiempo real, comportamiento de tus usuarios y crear modelos que mejoren financias y predigan la forma de hacer mejores inversiones. 

El **Data Analytics** es importante para las empresas sin importar su tama√±o, sin ello las decisiones serian tomadas por intuici√≥n o suerte. 

La data se puede generar de varias formas, recopilando clics de una p√°gina web, trav√©s de una API, encuestas, bases de datos locales, si sab√©s donde mirar pr√°cticamente todo es data. El desaf√≠o est√° en almacenarla en un mismo lugar, crear Data Lakes, para poder hacer cruces y an√°lisis con ella, hacer uso de ella. 

En este blog te voy a mostrar c√≥mo crear un peque√±o pipeline de **Data Analytics**, donde se deja un archivo en un storage y de ah√≠ es procesado para crear una tabla dentro de una base de datos de la cual se alimenta un dasboard de Business Inteligence. 

Y.. Lo podr√°s desplegar listo para usar con un par de comandos usando [CDK](https://aws.amazon.com/es/cdk/?nc1=h_ls) üöÄ üë©üèª‚ÄçüöÄ.

---

## La Soluci√≥n ü§î ‚öôÔ∏è

![fase1](imagen/fase1.jpg)

1. Se deja el archivo en el Bucket de [Amazon S3](https://aws.amazon.com/es/s3/), lo cual activa la [AWS Lambda](https://aws.amazon.com/es/lambda/) que gatilla el [AWS Glue Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html).
2. El [AWS Glue Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html) explora el nuevo archivo, y en paralelo gatilla un evento en EnventBridge que aciva la [AWS Lambda](https://aws.amazon.com/es/lambda/) encargada de actualizar a QuickSight una vez finalice la exploraci√≥n. 
3. Una vez finalizada la exploracion de [AWS Glue Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html) este actualiza el [AWS Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html) , el cual a su vez actualiza la tabla en [Amazon Athena](https://aws.amazon.com/es/athena/) , el [Amazon EventBridge](https://aws.amazon.com/es/eventbridge/) informa a la [AWS Lambda](https://aws.amazon.com/es/lambda/) para que pueda actualizar el almacenamiento de Spice en [Amazon QuickSight](https://aws.amazon.com/es/quicksight/) desde la data en [Amazon Athena](https://aws.amazon.com/es/athena/). 
4. Queda el DashBoard de [Amazon QuickSight](https://aws.amazon.com/es/quicksight/) listo para hacer Data Analytics.  

---

## Despliegue üöÄ üë©üèª‚ÄçüöÄ


**Para crear la aplicaci√≥n en tu cuenta AWS debes seguir los siguientes pasos:**

### 1. Instalar CDK

Para realizar el despliegue de los recursos, debes instalar y configurar la cli (command line interface) de CDK, en este caso estamos utilizando CDK con Python.

[Instalaci√≥n y configuraci√≥n de CDK](https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html)

[Documentaci√≥n CDK para Python](https://docs.aws.amazon.com/cdk/api/latest/python/index.html)


### 2. Clonamos el repo y vamos la carpeta de nuestro proyecto. 

```bash
git clone https://github.com/elizabethfuentes12/first-steps-with-analytics-in-aws
cd first-steps-with-analytics-in-aws/first-steps-abalytics
```

### 3. Creamos e iniciamos el ambiente virtual

```bash
python3 -m venv .venv
source .venv/bin/activate
```

Este ambiente virtual (venv) nos permite aislar las versiones del python que vamos a utilizar como tambi√©n de librer√≠as asociadas. Con esto podemos tener varios proyectos con distintas configuraciones.


### 4. Instalamos los requerimientos para el ambiente de python 

Para que el ambiente pueda desplegarse, debemos agregar todas las librer√≠as CDK necesarias en el archivo  [requirements.txt](https://github.com/elizabethfuentes12/AWS_ScanVideoS3Rekognition/blob/main/ScanVideoS3Rekognition/requirements.txt)


```zsh
pip install -r requirements.txt
```

### 5. Desplegando la aplicaci√≥n

Previo al despliegue de la aplicaci√≥n en AWS Cloud debemos asegurarnos que este sin errores para que no salten errores durante el despliegue, eso lo hacemos con el siguiente comando que genera un template de cloudformation con nuestra definici√≥n de recursos en python.

```bash
cdk synth
```

Si hay alg√∫n error en tu c√≥digo este comando te indicara cual es con su ubicaci√≥n.  

En el caso de estar cargando una nueva versi√≥n de la aplicaci√≥n puedes revisar que es lo nuevo con el siguiente comando: 

```
cdk diff
```

Procedemos a desplegar la aplicaci√≥n: 

```
cdk deploy
```

### 7. Tips Para el despliegue


El despliegue lo utiliza utilizando las credenciales por defecto de AWS, si desea usar un profile espec√≠fico agregue --profile <nombre> al comando deploy:

```
cdk deploy --profile mi-profile-custom
```

o simplemente exporte en una variable de entorno

```
export AWS_PROFILE=mi-profile-custom
cdk deploy
```

---

### 8. La aplicaci√≥n




---

### 9. Eliminar el stack de la aplicaci√≥n

Esta aplicaci√≥n no elimina el bucket si contiene videos, por lo que primero debes vaciar el bucket y luego proceder a destruir el stak. 


Para eliminar el stack lo puedes hacer via comando:

```
cdk destroy
```

√≥ via consola cloudformation, seleccione el stack (mismo nombre del proyecto cdk) y lo borra.

## ¬°¬°Happy developing üòÅ!!


---


## Adicional ü§î ‚öôÔ∏è üß∞

![fase2](imagen/fase2.jpg)

En este adicional, en vez de dejar un archivo en [Amazon S3](https://aws.amazon.com/es/s3/) se deja en una carpeta de OneDrive. 

1. Se deja el archivo en la carpeta de OneDrive, la cual esta siendo escuchada con un Webhook en [Amazon API Gateway](https://aws.amazon.com/es/api-gateway/). 
2. [Amazon API Gateway](https://aws.amazon.com/es/api-gateway/) activa una [AWS Lambda](https://aws.amazon.com/es/lambda/) encargada de extraer la data de OneDrive y copiarla en S3, para que esto sea posible la Lambda debe obtener el Token y refresh_token desde [AWS Secrets Manager](https://aws.amazon.com/es/secrets-manager/). 
4. Retomamos el paso 1 de la arquitectura de la solucion anterior. 


El c√≥digo para lograr esta solucion se encontrara proximamente en los siguientes enlaces: 

Configuraci√≥n Lambda Funtcion paso 2. 
Configuraci√≥n API Gateway.
Condiguraci√≥n Secrets Manager. 

___

## Servicios involucrados en la soluci√≥n son

### Amazon S3 (Simple Storage Service):
[Amazon S3](https://aws.amazon.com/es/s3/) es un servicio de computo sin servidor que le permite ejecutar c√≥digo sin aprovisionar ni administrar servidores.

### AWS Lamdba: 
[AWS Lambda](https://aws.amazon.com/es/lambda/) es un servicio de computo sin servidor que le permite ejecutar c√≥digo sin aprovisionar ni administrar servidores. 

### AWS Glue Crawler: 
[AWS Glue Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html) Es un servicio de AWS, que te permite desubrir data, reconoce su esquema o columnas, el tipos de dato, arma un catalogo de glue. Se puede ejecutar a demanda o agendados. 

### AWS Glue Data Catalog: 
[AWS Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html) contiene referencias a los datos, es un √≠ndice de la ubicaci√≥n,al esquema y al tiempo de creaci√≥n. La informaci√≥n en los catalogos se almacena como tablas de metadatos, donde cada tabla hace referencia a un √∫nico almacen de datos. 

### Amazon Athena: 
[Amazon Athena](https://aws.amazon.com/es/athena/) es un servicio de consultas interactivo que facilita el an√°lisis de datos en Amazon S3 con SQL est√°ndar. Athena no tiene servidor, de manera que no es necesario administrar infraestructura y solo paga por las consultas que ejecuta.

### Amazon EventBridge: 
[Amazon EventBridge](https://aws.amazon.com/es/eventbridge/) es un bus de eventos sin servidor que facilita la creaci√≥n de aplicaciones basadas en eventos a escala mediante eventos generados por sus aplicaciones, aplicaciones integradas de software como servicio (SaaS) y servicios de AWS.

### Amazon QuickSight: 
[Amazon QuickSight](https://aws.amazon.com/es/quicksight/) es un servicio de an√°lisis empresarial muy r√°pido, f√°cil de utilizar y administrado en la nube que facilita a todos los empleados de una organizaci√≥n la compilaci√≥n de visualizaciones, la realizaci√≥n de an√°lisis ad-hoc y la obtenci√≥n r√°pida de informaci√≥n empresarial a partir de sus datos en cualquier momento y en cualquier dispositivo.

### Amazon API Gateway: 
[Amazon API Gateway](https://aws.amazon.com/es/api-gateway/) es un servicio completamente administrado que facilita a los desarrolladores la creaci√≥n, la publicaci√≥n, el mantenimiento, el monitoreo y la protecci√≥n de API a cualquier escala. Las API act√∫an como la "puerta de entrada" para que las aplicaciones accedan a los datos, la l√≥gica empresarial o la funcionalidad de sus servicios de backend. 

### AWS Secrets Manager: 
[AWS Secrets Manager](https://aws.amazon.com/es/secrets-manager/) le ayuda a proteger los datos confidenciales necesarios para acceder a sus aplicaciones, servicios y recursos de TI. El servicio le permite alternar, administrar y recuperar f√°cilmente credenciales de bases de datos, claves de API y otros datos confidenciales durante su ciclo de vida. Los usuarios y las aplicaciones recuperan datos confidenciales con una llamada a las API de Secrets Manager, lo que elimina la necesidad de codificar informaci√≥n confidencial en texto sin formato


### CDK (Cloud Development Kit): 
El kit de desarrollo de la nube de AWS (AWS CDK) es un framework de c√≥digo abierto que sirve para definir los recursos destinados a aplicaciones en la nube mediante lenguajes de programaci√≥n conocidos.

Una vez lo conozcas... no vas a querer desarrollar aplicaciones en AWS de otra forma ;)

Conoce m√°s ac√°: [CDK](https://aws.amazon.com/es/cdk/?nc1=h_ls)


---

## ¬°Gracias!

Te dejo mis redes para que me sigas: 

[Dev.to](https://dev.to/elizabethfuentes12)

[Linkedin](https://www.linkedin.com/in/lizfue/)

[GitHub](https://github.com/elizabethfuentes12/)

[Twitter](https://twitter.com/elizabethfue12)

üáªüá™üá®üá±